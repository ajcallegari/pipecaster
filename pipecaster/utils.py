from inspect import signature, getfullargspec
import sklearn.base
import joblib
import ray

__all__ = ['is_classifier', 'is_regressor', 'is_predictor', 'is_transformer'
           'detect_estimator_type', 'is_multichannel',
           'get_clone', 'get_sklearn_clone', 'get_list_clone',
           'save_model', 'load_model', 'get_transform_method', 'get_predict_method', 
           'is_predictor', 'FitError', 'ParallelBackendError', 'get_descriptor', 
           'get_param_names', 'get_param_clone', 'Cloneable', 'Saveable', 'encode_labels']

# defines the methods used by pipecaster to detect predictor objects and make predictions
recognized_pred_methods = set(['predict', 'predict_proba', 'decision_function', 'predict_log_proba'])
    
def is_classifier(obj):
    """
    Detect a classifier algorithm.
    """    
    if hasattr(obj, '_estimator_type'):
        if getattr(obj, '_estimator_type', None) == 'classifier':
            return True
    elif hasattr(obj, 'classes_'):
        return True
    else:
        return False
     
def is_regressor(obj):
    """
    Detect a regressor algorithm.
    """
    if hasattr(obj, '_estimator_type'):
        if getattr(obj, '_estimator_type', None) == 'regressor':
            return True
    elif hasattr(obj, 'classes_'):
        return False
    else:
        return False
    
def is_predictor(pipe):
    """
    Detect a predictor algorithm.
    """
    for method in recognized_pred_methods:
        if hasattr(pipe, method):
            return True
    return False

def is_transformer(pipe):
    """
    Detect a transformer algorithm.
    """
    if hasattr(pipe, 'transform'):
        return True
    else:
        return False
    
def detect_estimator_type(pipe):
    """
    Determine if an algorithm is a classifier, regressor, or neither (unknown).
    """
    if is_classifier(pipe):
        _estimator_type = 'classifier'
    elif is_regressor(pipe):
        _estimator_type = 'regressor'
    else:
        _estimator_type = 'unknown'
    return _estimator_type

def enforce_fit(pipe):
    """
    Throw error if pipe lacks a required fit method.
    """
    if hasattr(pipe, 'fit'):
        return
    else:
        raise TypeError('{} lacks a required fit method'.format(pipe.__class__.__name__))
        
def enforce_predict(pipe):
    """
    Throw error if pipe lacks a recognized method for predicting.
    """
    if is_predictor(pipe):
        return
    else:
        raise TypeError('{} lacks a recognized method for prediction'.format(pipe.__class__.__name__))
        
def enforce_output(pipe):
    """
    Throw error if pipe has no recognized method for generating outpub (predicting or transforming).
    """
    if is_predictor(pipe) or is_transformer(pipe):
        return
    else:
        raise TypeError('{} lacks a required method for generating output (tranform or predict)'
                        .format(pipe.__class__.__name__))
        
def check_pipe_interface(pipe):
    """
    Throw error if pipe lack a fit method or has no recognized method for generating output.
    """
    enforce_fit(pipe)
    enforce_output(pipe)

def is_multichannel(pipe):
    """
    Detect if a pipeline component is multi-input by determining if the first argument to fit() is 'Xs' 
    """
    first_param = list(signature(pipe.fit).parameters.keys())[0]
    return first_param == 'Xs'

def get_prediction_method_names(pipe):
    """
    Return a list of all recongized prediction methods or None
    """
    return [m for m in recognized_pred_methods if hasattr(pipe, m)]

def get_clone(pipe, disable_custom_cloning=False):
    
    """Get a new copy of a transformer/estimator/predictor instance. 
    Parameters
    ----------
    pipe : transformer, estimator, predictor
        Pipeline building block
    disable_custom_cloning : bool
        Flag that disables use of the pipe.get_clone() method
    Returns
    -------
    New transformer/estimator/predictor instance generated by the pipe.get_clone() method, if there is one. If not, the returned instance is created by the generic sklearn.base.clone() function which basically does: pipe.__class__(**pipe.get_params())
    Notes
    -----
    Cutoming cloning via pipe.get_clone() has been added in Pipecaster to enable neural net warm starts that don't conform to sklearn's stateless cloning mechanism.
    """
    
    if hasattr(pipe, 'get_clone') and disable_custom_cloning == False:
        return pipe.get_clone()
    else:
        return sklearn.base.clone(pipe)
    
def get_sklearn_clone(pipe):
    return get_clone(pipe, disable_custom_cloning=True)
    
def get_clones(pipes):
    if isinstance(pipes, (list, tuple, np.ndarray)):
        return [get_clone(p) if p is not None else None for p in pipes]
    else:
        return get_clone(pipes) if p is not None else None
    
def save_model(model, filepath):
    joblib.dump(model, filepath) 
    
def load_model(filepath):
    return joblib.load(filepath) 

class FitError(Exception):
    """Exception raised when calls to fit() fail
    """
    def __init__(self, message="call to fit() method failed"):
        self.message = message
        super().__init__(self.message)
        
class ParallelBackendError(Exception):
    """Exception raised when a distributed backend function fails
    """
    def __init__(self, message='request to the parallel backend failed'):
        self.message = message
        super().__init__(self.message)
        
def get_descriptor(class_name, params, verbose = True):
        string_ = class_name + '('
        
        if verbose:
            argstrings = []
            for k, v in params.items():
                argstring = k + '=' 
                if hasattr(v, '__name__'):
                    argstring += v.__name__
                elif hasattr(v, '__str__'):
                    argstring += v.__str__()
                elif type(v) in [str, int, float]:
                    argstring += v
                else:
                    argstring += 'NA'
                argstrings.append(argstring)
            string_ += ', '.join(argstrings)
                    
        return  string_ + ')'
    
def get_param_names(callable_, omit_self = True):
    param_names = set(getfullargspec(callable_)[0])
    if omit_self:
        param_names.remove('self')
    return param_names

def get_param_clone(pipe):
    return pipe.__class__(**pipe.get_params())

class Cloneable:
    
    state_variables = [] # override me with a list of state attributes to copy on calls to get_clone
        
    @property
    def param_names(self):
        return get_param_names(self.__init__)
                
    def _init_params(self, locals_):
        for param_name in self.param_names:
            setattr(self, param_name, locals_[param_name])
    
    def __str__(self, verbose=True):
        return get_descriptor(self.__class__.__name__, self.get_params(), verbose)
    
    def __repr__(self):
        return self.__str__(verbose=True)  
    
    def get_params(self, deep=False):
        return {p:getattr(self,p) for p in self.param_names}
    
    def set_params(self, params):
        for key, value in params.items():
            if key in self.__class__.params:
                setattr(self, key, value)
            else:
                raise AttributeError('invalid parameter name')
    
    def get_clone(self):
        clone = get_param_clone(self)
        for var in self.__class__.state_variables:
            if hasattr(self, var):
                setattr(clone, var, getattr(self, var))
        return clone
    
class Saveable:
    
    def save(self, filepath):
        joblib.dump(self, filepath)
        
    @staticmethod
    def load(filepath):
        return joblib.load(filepath) 
    
def encode_labels(y):
    if isinstance(y, np.ndarray) and len(y.shape) > 1 and y.shape[1] > 1:
        raise NotImplementedError('Multilabel and multi-output meta-classification not supported')
    classes_, y = np.unique(y, return_inverse=True)
    return classes_, y_encoded