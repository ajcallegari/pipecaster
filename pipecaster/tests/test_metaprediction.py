import timeit
import multiprocessing
import ray
import numpy as np
import unittest
import warnings 

from sklearn.datasets import make_classification
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score

import sklearn.model_selection
import pipecaster.metaprediction

class TestSplitPredict(unittest.TestCase):
    
    def setUp(self):
        self.clf = RandomForestClassifier(n_estimators=20, random_state = 42)
        self.X, self.y = make_classification(n_samples=500, 
                                   n_features=400, 
                                   n_informative=200, 
                                   n_redundant=5,
                                   n_repeated=5,
                                   class_sep=1)
        
        self.sklearn_predictions = sklearn.model_selection.cross_val_predict(self.clf, self.X, self.y, cv = 5, n_jobs = 1)
        self.sklearn_auc = roc_auc_score(self.y, self.sklearn_predictions)

    def test_predictions(self):
        
        clf, X, y = self.clf, self.X, self.y

        pipecaster_predictions = pipecaster.metaprediction.split_predict(clf, X, y, cv = 5, n_jobs = 1)
        pipecaster_auc = roc_auc_score(y, self.sklearn_predictions)
        
        self.assertTrue(np.array_equal(self.sklearn_predictions, pipecaster_predictions),
                        'predictions from pipecaster.metaprediction.split_predict did not match sklearn version')

        self.assertTrue(self.sklearn_auc == pipecaster_auc,
                'auc of pipecaster.metaprediction.split_predict did not match sklearn version')
            
        self.assertTrue(pipecaster_auc > 0.5,
                'auc of pipecaster.metaprediction.split_predict was not better than random')
            
    def test_multiprocessing(self):
        clf, X, y = self.clf, self.X, self.y
        n_cpus = multiprocessing.cpu_count()

        if n_cpus > 1:
            # shut off warnings because ray and redis generate massive numbers
            warnings.filterwarnings("ignore")
            try:
                ray.nodes()
            except RuntimeError:
                ray.init()
            
            SETUP_CODE = ''' 
import pipecaster.model_selection'''
            TEST_CODE = ''' 
pipecaster.metaprediction.split_predict(clf, X, y, cv = 5, n_jobs = 1)'''
            t_serial = timeit.timeit(setup = SETUP_CODE, 
                                  stmt = TEST_CODE, 
                                  globals = locals(), 
                                  number = 5) 
            TEST_CODE = ''' 
pipecaster.metaprediction.split_predict(clf, X, y, cv = 5, n_jobs = {})'''.format(n_cpus)
            t_parallel = timeit.timeit(setup = SETUP_CODE, 
                                  stmt = TEST_CODE, 
                                  globals = locals(), 
                                  number = 5) 
    
            if t_serial <= t_parallel:
                warnings.warn('parallel cross_val_predict not faster than serial, likely issue with ray multiprocessing')

            parallel_predictions = pipecaster.metaprediction.split_predict(clf, X, y, cv = 5, n_jobs = n_cpus)
            parallel_auc = roc_auc_score(y, parallel_predictions)
            warnings.resetwarnings()
            
            self.assertTrue(np.array_equal(self.sklearn_predictions, parallel_predictions), 
                            'the predictions generated by parallel run of pipecaster.metaprediction.split_predict \
                             did not match sklearn control')
                        
            self.assertTrue(self.sklearn_auc == parallel_auc, 
                            'the auc of predictions generated by parallel run of pipecaster.metaprediction.split_predict \
                             did not match sklearn control')

            self.assertTrue(parallel_auc > 0.5, 
                            'the predictions generated by parallel run of pipecaster.metaprediction.split_predict \
                             did not match sklearn control')

if __name__ == '__main__':
    unittest.main()