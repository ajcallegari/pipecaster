{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Separate pipelines for each input matrix\n",
    "\n",
    "### Rationale\n",
    "\n",
    "1. When using multiple features matrices as inputs for a single ML task, accuracy is sometimes better in practice if a separate model is trained on each feature matrix and the inference is made by voting or model stacking (as opposed to concatanating all of the inputs together into a single matrix).  This may be due to averaging out of overfitting errors from the individual models.  \n",
    "\n",
    "2. When computational complexity for model training is non-linear with the number of features (e.g. fully-connected neural nets) it is much faster to train models on each input matrix than on a single pooled feature matrix.   \n",
    "\n",
    "3. The adage \"garbage in, garbage out\" is still true for machine learning models, even though they are good at minimizing noise.  Sometimes it's useful to winnow out the less predictive feature matrices in order to prevent overfitting.  This winnowing, called \"feature matrix selection\" here, is simpler when the matrices are kept separate.\n",
    "\n",
    "4. Workflows that involve optimizing ML pipelines for a large number of different tasks at the same time can be faster if feature matrix selection is included in each pipeline rather than screened independently.  This might be considered semi-auto-ML.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipecaster as pc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_matrices = 100\n",
    "n_features = 50\n",
    "\n",
    "X, y = make_classification(n_classes = 2, \n",
    "                           n_samples = 200, \n",
    "                           n_features= n_features * n_matrices,\n",
    "                           n_informative= 5 * n_matrices, \n",
    "                           n_redundant= 5 * n_matrices)\n",
    "\n",
    "matrices = []\n",
    "for i in range(n_matrices):\n",
    "    matrices.append(X[:, i*n_features : (i+1) * n_features])\n",
    "    \n",
    "X_trains, X_tests, y_train, y_test = pc.split(Xs, y, train_test_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipecaster as pc\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# X_new = SelectKBest(chi2, k=2).fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.rand(100,5)\n",
    "y = np.random.choice(['a','b','c'], 100)\n",
    "\n",
    "cls = KNeighborsClassifier()\n",
    "cls.fit(X, y)\n",
    "cls.predict_proba(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.predict_proba(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pl = pc.PipelineArray(inputs)\n",
    "pl.add_layer([SimpleImputer() for i in range(5)] + [CountVectorizer()])\n",
    "pl.add_layer([StandardScaler() for i in range(5)] + [TfidfTransformer()])\n",
    "pl.add_layer(MatrixSelector(inputs = range(5)) # implicit: PassThrough(input = 6) \n",
    "pl.add_layer(SelectKBest(chi2))\n",
    "pl.add_layer(Concatentor())\n",
    "pl.split([(0, 3), (1, 3), (2, 3), (3, 3), (4, 3), (5, 3), (6, 3)])\n",
    "cls1 = CvEstimator(estimator = LogisticRegression(), cv = ShuffleSplit, scoring = roc_auc_score)\n",
    "cls2 = CvEstimator(estimator = KNeighborsClassifier(), cv = ShuffleSplit, scoring = roc_auc_score)\n",
    "cls3 = CvEstimator(estimator = RandomForestClassifier(), cv = ShuffleSplit, scoring = roc_auc_score)\n",
    "cls4 = MultinomialNB()\n",
    "cls5 = SGDClassifier()\n",
    "pl.add_layer([cls1, cls2, cls3, cls1, cls2, cls3, cls1, cls2, cls3, \n",
    "              cls1, cls2, cls3, cls1, cls2, cls3, cls4, cls5])\n",
    "pl.add_layer(PerformanceSelector(top_n = 2))\n",
    "pl.add_layer()\n",
    "cls6 = SVC()\n",
    "pl.add_layer(cls6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([[2],[2],None,None], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    x = np.arange(100,110)\n",
    "    \n",
    "x = np.arange(10)\n",
    "f(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# architecture 1 (diverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_arr = pc.PipelineArray(n_inputs=6)\n",
    "\n",
    "layer1 = pipe_arr.next_layer() # get new layer array of length n_inputs, all initialized to PassThrough()\n",
    "layer1[:6] = SimpleImputer() \n",
    "layer1[6] = CountVectorizer()\n",
    "\n",
    "layer2 = pipe_arr.next_layer()\n",
    "layer2[:6] = StandardScaler()\n",
    "layer2[6] = TfidfTransformer()\n",
    "\n",
    "layer3 = pipe_arr.next_layer()\n",
    "layer3[:7] = pc.SelectKBestMatrices(scoring=roc_auc_score, aggregator='mean', k=3)\n",
    "\n",
    "layer4 = pipe_arr.next_layer() # automatically add layer[:6] = PassThrough()\n",
    "layer4[:] = SelectKBest(chi2, k = 100)\n",
    "\n",
    "layer5 = pipe_arr.next_layer()\n",
    "cls1 = CvEstimator(estimator = LogisticRegression(), cv = ShuffleSplit, scoring = roc_auc_score)\n",
    "cls2 = CvEstimator(estimator = KNeighborsClassifier(), cv = ShuffleSplit, scoring = roc_auc_score)\n",
    "cls3 = CvEstimator(estimator = RandomForestClassifier(), cv = ShuffleSplit, scoring = roc_auc_score)\n",
    "cls4 = MultinomialNB()\n",
    "cls5 = SGDClassifier()\n",
    "layer5[:6] = [cl1, cls2, cls3] # create an ensemble\n",
    "layer5[6] = [cls4, cls5] # create an ensemble\n",
    "\n",
    "layer6 = pipe_arr.next_layer()\n",
    "layer6[:6] = pc.SelectKBestPerformers(scoring=roc_auc_score, k=2)\n",
    "\n",
    "layer7 = pipe_arr.next_layer()\n",
    "layer7[:6] = pc.EnsembleConcatenator()\n",
    "\n",
    "layer8 = pipe_arr.next_layer()\n",
    "layer8[:7] = pc.PipelineConcatenator()\n",
    "\n",
    "layer9 = pipe_arr.next_layer()\n",
    "layer9 = SVC()\n",
    "\n",
    "pipe_arr.fit(X_trains, y_train)\n",
    "pipe_arr.predict(Xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# architecture 2 (nested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "my_classifier = pc.PipelineArray(n_inputs=1)\n",
    "\n",
    "my_classifier.add_layer(SimpleImputer())\n",
    "my_classifier.add_layer(StandardScaler())\n",
    "my_classifier.add_layer([PCA(n_components=10), \n",
    "                         FactorAnalysis(n_components=10),\n",
    "                         SelectKBest(chi2, k = 100)])\n",
    "\n",
    "my_classifier.next_layer() = \n",
    "\n",
    "layer2 = my_classifier.next_layer()\n",
    "layer2[:6] = StandardScaler()\n",
    "layer2[6] = TfidfTransformer()\n",
    "\n",
    "layer3 = my_classifier.next_layer()\n",
    "layer3[:7] = pc.SelectKBestMatrices(scoring=roc_auc_score, aggregator='mean', k=3)\n",
    "\n",
    "layer4 = pipe_arr.next_layer() # automatically add layer[:6] = PassThrough()\n",
    "layer4[:] = SelectKBest(chi2, k = 100)\n",
    "\n",
    "layer5 = pipe_arr.next_layer()\n",
    "cls1 = CvEstimator(estimator = LogisticRegression(), cv = ShuffleSplit, scoring = roc_auc_score)\n",
    "cls2 = CvEstimator(estimator = KNeighborsClassifier(), cv = ShuffleSplit, scoring = roc_auc_score)\n",
    "cls3 = CvEstimator(estimator = RandomForestClassifier(), cv = ShuffleSplit, scoring = roc_auc_score)\n",
    "cls4 = MultinomialNB()\n",
    "cls5 = SGDClassifier()\n",
    "layer5[:6] = [cl1, cls2, cls3] # create an ensemble\n",
    "layer5[6] = [cls4, cls5] # create an ensemble\n",
    "\n",
    "layer6 = pipe_arr.next_layer()\n",
    "layer6[:6] = pc.SelectKBestPerformers(scoring=roc_auc_score, k=2)\n",
    "\n",
    "layer7 = pipe_arr.next_layer()\n",
    "layer7[:6] = pc.EnsembleConcatenator()\n",
    "\n",
    "layer8 = pipe_arr.next_layer()\n",
    "layer8[:7] = pc.PipelineConcatenator()\n",
    "\n",
    "layer9 = pipe_arr.next_layer()\n",
    "layer9 = SVC()\n",
    "\n",
    "pipe_arr.fit(X_trains, y_train)\n",
    "pipe_arr.predict(Xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# architecture 3 (diverse, no ensembling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = pc.PipelineArray(n_inputs=6)\n",
    "\n",
    "layer0 = cls.get_next_layer() # get new layer array of length n_inputs, all initialized to PassThrough()\n",
    "layer0[:6] = SimpleImputer() \n",
    "layer0[6] = CountVectorizer()\n",
    "\n",
    "layer1 = cls.get_next_layer()\n",
    "layer1[:6] = StandardScaler()\n",
    "layer1[6] = TfidfTransformer()\n",
    "\n",
    "layer2 = cls.get_next_layer()\n",
    "layer2[:7] = pc.SelectKBestMatrices(scoring=f_classif, aggregator='mean', k=3)\n",
    "\n",
    "layer3 = cls.get_next_layer() # automatically add layer[:6] = PassThrough()\n",
    "layer3[:] = SelectKBest(f_classif, k = 100)\n",
    "\n",
    "layer4 = cls.get_next_layer()\n",
    "cls1 = CvEstimator(estimator = LogisticRegression(), cv = ShuffleSplit, scoring = roc_auc_score)\n",
    "cls2 = CvEstimator(estimator = KNeighborsClassifier(), cv = ShuffleSplit, scoring = roc_auc_score)\n",
    "cls3 = CvEstimator(estimator = RandomForestClassifier(), cv = ShuffleSplit, scoring = roc_auc_score)\n",
    "cls4 = MultinomialNB()\n",
    "cls5 = SGDClassifier()\n",
    "layer4[:6] = [cl1, cls2, cls3] # create an ensemble\n",
    "layer4[6] = [cls4, cls5] # create an ensemble\n",
    "\n",
    "layer5 = cls.get_next_layer()\n",
    "layer5[:6] = pc.SelectKBestPerformers(scoring=roc_auc_score, k=2)\n",
    "\n",
    "layer6 = cls.get_next_layer()\n",
    "layer6[:6] = pc.EnsembleConcatenator()\n",
    "\n",
    "layer7 = cls.get_next_layer()\n",
    "layer7[:7] = pc.PipelineConcatenator()\n",
    "\n",
    "layer8 = cls.get_next_layer()\n",
    "layer8 = SVC()\n",
    "\n",
    "my_classifier.fit(X_trains, y_train)\n",
    "my_classifier.predict(Xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# architecture 4 (no storing of scores for future steps)\n",
    "\n",
    "In this architecture, it is assumed that there is no caching or passing of model accuracy scores to allow selection at a subsequent layer.  So model performance scoring and seletion is done in a single step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgr = KNeighborsRegressor()\n",
    "rgr.fit(np.arange(300).reshape(100,3), np.random.rand(100))\n",
    "x = rgr.predict(np.arange(300).reshape(100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.reshape(-1,1)\n",
    "len(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(np.arange(300).reshape(100,3), np.random.choice(['a','b','c'], size = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(np.arange(300).reshape(100,3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['c', 'c', 'c', 'c', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'a', 'a', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'a', 'a',\n",
       "       'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a',\n",
       "       'a', 'a', 'b', 'b', 'b', 'b', 'c', 'c', 'b', 'c', 'c', 'c', 'b',\n",
       "       'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'b', 'c', 'c', 'c', 'c',\n",
       "       'c', 'c', 'a', 'a', 'a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'c', 'b', 'a', 'c', 'a', 'a', 'a', 'b',\n",
       "       'a', 'b', 'b', 'a', 'a', 'b', 'b', 'b', 'b'], dtype='<U1')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(np.arange(300).reshape(100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(np.arange(300).reshape(100,3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(100)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.empty((100, 2))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(np.arange(9).reshape(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3])\n",
    "y = list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "rgr = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgr.fit(np.arange(300).reshape(100,3), np.random.rand(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rgr.predict(np.arange(9).reshape(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = set([1,2,4])\n",
    "y = set([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.arange(0,3)\n",
    "x2 = np.arange(3,6)\n",
    "Xs = np.array([x1,x2], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d7736ab3e6ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs[inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pipecaster' from '/Users/john/trading/src/pipecaster/pipecaster-repo/pipecaster/__init__.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inputs = 6\n",
    "set(range(n_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    x[2] = 222\n",
    "\n",
    "x = np.arange(9)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1, 222,   3,   4,   5,   6,   7,   8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipecaster as pc\n",
    "\n",
    "mcls = pc.MultiInputPipeline(n_inputs=6)\n",
    "\n",
    "layer0 = mcls.get_next_layer() # get new layer array of length n_inputs, all initialized to PassThrough()\n",
    "layer0[:5] = SimpleImputer() \n",
    "layer0[5] = CountVectorizer()\n",
    "\n",
    "layer1 = mcls.get_next_layer()\n",
    "layer1[:5] = StandardScaler()\n",
    "layer1[5] = TfidfTransformer()\n",
    "\n",
    "layer2 = mcls.get_next_layer() \n",
    "layer2[:] = SelectKBest(f_classif, k = 100)\n",
    "\n",
    "layer3 = mcls.get_next_layer()\n",
    "layer3[:5] = pc.SelectKBestInputs(score_func=f_classif, aggregator=np.sum, k=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<pipecaster.input_selection.SelectKBestInputs at 0x127553510>,\n",
       "  array([0, 1, 2, 3, 4]))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcls.layers[3].pipe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pipecaster' has no attribute 'SelectKBestPredictors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-323e0afcc0c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlayer4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpredictors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlayer4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSelectKBestPredictors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mlayer4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pipecaster' has no attribute 'SelectKBestPredictors'"
     ]
    }
   ],
   "source": [
    "layer4 = mcls.get_next_layer()\n",
    "predictors = [KNeighborsClassifier() for i in range(5)]\n",
    "layer4[:5] = pc.SelectKBestPredictors(predictors=predictors, scoring=make_scorer(roc_auc_score), cv=3)\n",
    "layer4[5] = MultinomialNB()\n",
    "\n",
    "layer5 = mcls.get_next_layer()\n",
    "layer5[:] = pc.MetaClassifier(SVC())\n",
    "\n",
    "mcls.fit(X_trains, y_train)\n",
    "mcls.predict(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# architecture 4 (all numerical for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclf = pc.MultiInputPipeline(n_inputs=6)\n",
    "\n",
    "layer0 = mclf.get_next_layer() # get new layer array of length n_inputs, all initialized to PassThrough()\n",
    "layer0[:5] = SimpleImputer() \n",
    "layer0[5] = CountVectorizer()\n",
    "\n",
    "layer1 = mclf.get_next_layer()\n",
    "layer1[:5] = StandardScaler()\n",
    "layer1[5] = TfidfTransformer()\n",
    "\n",
    "layer2 = mclf.get_next_layer() # automatically add layer[:6] = PassThrough()\n",
    "layer2[:] = SelectKBest(f_classif, k = 100)\n",
    "\n",
    "layer3 = mclf.get_next_layer()\n",
    "layer3[:5] = pc.SelectKBestMatrices(scoring=f_classif, aggregator='sum', k=3)\n",
    "\n",
    "layer4 = mclf.get_next_layer()\n",
    "predictors = [KNeighborsClassifier() for i in range(5)]\n",
    "layer4[:5] = pc.SelectKBestPredictors(predictors=predictors, scoring=make_scorer(roc_auc_score), cv=3)\n",
    "layer4[5] = MultinomialNB()\n",
    "\n",
    "layer5 = mclf.get_next_layer()\n",
    "layer5[:] = pc.MetaClassifier(SVC())\n",
    "\n",
    "mclf.fit(X_trains, y_train)\n",
    "mclf.predict(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn colum transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "X_indices = [slice(1,100), slice(101,200), slice(201,300),\n",
    "             slice(301,400), slice(401,500), slice(501,600)]\n",
    "\n",
    "X_selectors = [ColumnTransformer([('X{}_selector'.format(i), 'passthrough', indices)])\n",
    "               for i, indices in enumerate(X_indices)]\n",
    "\n",
    "L0_classifiers = [Pipeline([('X{}_selector'.format(i), X_selector),\n",
    "                      ('imputer', SimpleImputer()), \n",
    "                      ('scaler', StandardScaler()), \n",
    "                      ('kbest', SelectKBest(f_classif, k = 20)),\n",
    "                      ('KNN', KNeighborsClassifier())])\n",
    "              for i, X_selector in enumerate(X_selectors[:-1])]\n",
    "    \n",
    "cls = Pipeline([('X6_selector', X_selectors[5]),\n",
    "                      ('count_vect', CountVectorizer()), \n",
    "                      ('tfid', TfidfTransformer()), \n",
    "                      ('kbest', SelectKBest(chi2, k = 20)),\n",
    "                      ('naive_bayes', MultinomialNB())])\n",
    "\n",
    "L0_classifiers.append(estimator)\n",
    "\n",
    "L0_classifier_list = [('cls_{}'.format(i), cls) for i, cls in enumerate(L0_classifiers)]\n",
    "\n",
    "my_cls = StackingClassifier(\n",
    "    estimators=L0_classifier_list, final_estimator=SVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rules:\n",
    "transform/estimator/predictor units are referred to as pipes for brevity\n",
    "each layer of the MultiPipeline has the same number of inputs that are referenced by their array indices\n",
    "a pipe always outputs to the same set of indices that it uses as input\n",
    "two pipes may not use the same input or the same output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "cls = KNeighborsClassifier()\n",
    "hasattr(cls, '__clone__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor()"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.base \n",
    "sklearn.base.clone(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 6\n",
    "\n",
    "def get_slice_indices(slice_):\n",
    "    return np.arange(6)[slice_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_ = slice(1, 3, None)\n",
    "get_slice_indices(slice_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "mat1 = np.arange(9).reshape(3,3)\n",
    "mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100, 101, 102],\n",
       "       [103, 104, 105],\n",
       "       [106, 107, 108]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat2 = 100 + mat1\n",
    "mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = np.array([mat1, mat2], dtype = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "ls1 = [1,2,3]\n",
    "ls2 = np.array(ls1)\n",
    "\n",
    "(type(cls) == list or type(cls) == np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not True and not False:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "if True and not False:\n",
    "    print(\"here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn test, numerical input only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "X_indices = [slice(0,100), slice(100,200), slice(200,300),\n",
    "             slice(300,400), slice(400,500)]\n",
    "\n",
    "X_selectors = [ColumnTransformer([('X{}_selector'.format(i), 'passthrough', indices)])\n",
    "               for i, indices in enumerate(X_indices)]\n",
    "\n",
    "L0_classifiers = [Pipeline([('X{}_selector'.format(i), X_selector),\n",
    "                      ('imputer', SimpleImputer()), \n",
    "                      ('scaler', StandardScaler()), \n",
    "                      ('kbest', SelectKBest(f_classif, k = 20)),\n",
    "                      ('KNN', KNeighborsClassifier())])\n",
    "              for i, X_selector in enumerate(X_selectors)]\n",
    "    \n",
    "L0_classifier_list = [('cls_{}'.format(i), cls) for i, cls in enumerate(L0_classifiers)]\n",
    "    \n",
    "\n",
    "my_cls = StackingClassifier(\n",
    "    estimators=L0_classifier_list, final_estimator=SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64071856, 0.69365486, 0.62160017])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = make_classification(n_samples=1000, n_features=500, n_informative=100, n_redundant=10)\n",
    "\n",
    "ctl_cls = KNeighborsClassifier()\n",
    "cross_val_score(ctl_cls, X, y, cv = 3, scoring = make_scorer(roc_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68862275, 0.70267297, 0.69071496])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(my_cls, X, y, cv = 3, scoring = make_scorer(roc_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.24655213e-01,  7.73561543e-03, -2.03583515e-01, ...,\n",
       "         1.85729466e+01, -3.85624280e-01,  2.42433946e-01],\n",
       "       [ 3.58305801e-01, -8.65509276e-01, -4.85829099e-01, ...,\n",
       "        -1.53111323e+01,  2.21342723e-01, -1.87359820e-02],\n",
       "       [ 1.69172439e+00, -4.42358621e-01,  1.09250570e+00, ...,\n",
       "        -2.49917111e+01, -1.04821565e+00, -9.89248874e-01],\n",
       "       ...,\n",
       "       [ 6.31516738e-01, -9.30686358e-02, -1.86402307e-01, ...,\n",
       "        -1.08200163e+01,  1.55595662e+00,  1.19938704e+00],\n",
       "       [ 1.19997306e+00,  1.46976992e-01, -1.88428710e+00, ...,\n",
       "        -5.03093792e+01,  7.14112674e-02, -1.36471996e+00],\n",
       "       [-5.70524600e-02,  3.00984653e+00, -7.30875298e-01, ...,\n",
       "        -2.35482832e+01,  5.76960915e-01,  8.55264803e-01]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_selectors[0].fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-004fb5302674>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mL0_classifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/trading/src/venv/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \"\"\"\n\u001b[1;32m    366\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mlast_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trading/src/venv/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trading/src/venv/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trading/src/venv/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trading/src/venv/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trading/src/venv/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mscore_func_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trading/src/venv/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py\u001b[0m in \u001b[0;36mchi2\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input X must be non-negative.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative."
     ]
    }
   ],
   "source": [
    "L0_classifiers[0].fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "Pipeline(steps=[('scaler', StandardScaler()), ('svc', SVC())])\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Matrix ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Matrix ensemble stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Matrix selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Transformer Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Transformer Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Semi-supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Pipeline Blueprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading_venv_clark",
   "language": "python",
   "name": "trading_venv_clark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "214px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
