# pipecaster
(in progress)

A scikit-learn extension library for building multi-input ML pipelines and for automating ML workflows.  Provides slice notation for broadcasting pipeline construction operations across multiple inputs and a Keras-like layered interface for building deep pipelines step-by-step.  Enables users to automate common screening tasks (data sources, feature engineering steps, ML algorithms, and hyperparameters) by including them in the ML pipeline.

# sample architecture
![Use case 1](/images/architecture_1.png)

This diagram shows a pipecaster classification pipeline taking 5 numerical input matrices (X0 to X4) and 1 text input (X5).  Code for building this pipeline is given below.  SelectKBestChannels computes a score for each input channel by aggregating their feature scores and then selects the k=3 best channels.  SelectKBestPredictors does an internal cross validation run within the training set during the call to pipeline.fit(Xs, y), estimates the accuracy of models trained on inputs 0 to 4, then selects the k=2 best models and sends their inferences on to a meta-classifier.

## sample code:

```
import pipecaster as pc  

clf = pc.Pipeline(n_inputs=6)

layer = clf.get_next_layer()
layer[:5] = SimpleImputer()
layer[5] = CountVectorizer()

layer = clf.get_next_layer()
layer[:5] = StandardScaler()
layer[5] = TfidfTransformer()

clf.get_next_layer()[:] = SelectKBest(f_classif, k = 100)

clf.get_next_layer()[:5] = pc.SelectKBestInputs(scoring=f_classif, aggregator='sum', k=3)

layer = clf.get_next_layer()
predictors = [KNeighborsClassifier() for i in range(5)]
layer[:5] = pc.SelectKBestPredictors(predictors=predictors,
                                     scoring=make_scorer(roc_auc_score), cv=3)
layer[5] = MultinomialNB()

clf.get_next_layer()[:] = pc.MetaClassifier(SVC())

clf.fit(X_trains, y_train)
clf.predict(X_tests)
```

# motivation

## input silos
ML libraries often implicitly encourage concatenation of features from multiple data sources into a single feature matrix (X) prior to feature selection or ML.  In practice, concatenation often reduces performance and greater predictive accuracy can be obtained by siloing the different inputs through the initial feature selection and ML steps and combining inferences at a later stage using voting or stacked generalization.  Pipecaster encourages input silos by modifying the sklearn interface from:  
`pipeline.fit(X, y).predict(X)`  
to   
`pipeline.fit(Xs, y).predict(Xs).`  

## in-pipeline screening
A typical ML workflow may involve screening different input sources, feature engineering steps, models, and model hyperparameters.  Pipecaster allows you to semi-automate each of these screening tasks by including them in the ML pipeline.  This can be useful when you are developing a large number of different pipelines in parallel and don't have time to optimize each one separately, and it may accelerate ML workflows in general.  I wasn't able to find these in-pipeline operations in scikit-learn, Dask, or Spark ML.

# features

## meta-prediction with input channel ensembles
Inferences generated by siloed input channels can easily be combined through voting and model stacking by layering pipecaster's ChannelClassifier/ChannelRegressor classes onto your pipeline (see example above).  This pipeline architecture can be also be built in scikit-learn by nesting ColumnTransformers within a VotingClassifier/VotingRegressor or within a StackingClassifier/StackingRegressor.  Pipecaster automatically detects predictors with outputs used in meta-classification and provides them with internal cross validation training(1) and transform()/fit_transform() methods.  
(1) Wolpert, David H. "Stacked generalization." Neural networks 5.2 (1992): 241-259.

## in-pipeline screening

**Input screening**   
The different input channels passed to pipecaster pipelines (Xs) may come from different data sources, different transformations of the data (i.e. for feature engineering), or both.  Pipecaster provides three ways to select input channels in order to keep garbage from flowing into and out of your ML models.    

  1. The *ScoreChannelSelector* class selects input channels based on aggregated feature scores.  
  1. The *PerformanceChannelSelector* class selects input channels based on performance of a probe model on an internal cross validation run.
  1. The *ChannelModelSelector* is similar to the PerformanceChannelSelector, but outputs the predictions of selected models rather passing through the values from the previous pipeline step.  

**Model screening**  
Pipecaster allows in-pipeline screening of ML models and their hyperparameters with the *SelectiveEnsemble* class.  A *SelectiveEnsemble*, which operates on a single input, is a voting or concatenating ensemble that selects only the most performant models from within the ensemble. Model performance is assessed with an internal cross validation run within the training set during calls to pipeline.fit().  

## fast multiprocessing and distributed computing
Pipecaster uses Ray to distribute cross validation runs and hyperparameter screens to multiple processors and computers.  Apart from enabling cluster computing, Ray dramatically increases the performance of single-computer multiprocessing performance relative to joblib multiprocessing or the Python standard library's multiprocessing package by distributing Python objects without serialization/de-serialization overhead using the plasma in-memory object store that is also used by Apache Arrow & Apache Spark.
